# ü¶ô Ollama Context Window Variant Generator

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Shell Script](https://img.shields.io/badge/Shell-Bash-green.svg)](https://www.gnu.org/software/bash/)
[![Ollama](https://img.shields.io/badge/Ollama-Compatible-blue.svg)](https://ollama.ai/)

A robust bash script that automatically generates Ollama model variants with different context window sizes. Perfect for testing and optimizing model performance across various context lengths.

## ‚ú® Features

- üîÑ **Automatic Variant Generation**: Creates model variants with context sizes from 8K up to the model's maximum capacity
- üõ°Ô∏è **Edge Case Handling**: Properly handles namespace/model names (e.g., `microsoft/DialoGPT`)
- üîß **Backward Compatibility**: Works with older Ollama versions by parsing plain text output
- üìÅ **Smart File Management**: Sanitizes model names for valid filenames
- ‚ö° **Batch Processing**: Processes all available models in one run
- üéØ **Selective Overwrite**: Choose whether to overwrite existing models/files
- üìä **Progress Tracking**: Clear progress indicators and status messages
- üö´ **Error Prevention**: Prevents silent exits with comprehensive error handling

## üöÄ Quick Start

### Prerequisites

- [Ollama](https://ollama.ai/) installed and running
- Bash shell (Linux/macOS/WSL)
- At least one Ollama model downloaded

### Installation

1. Clone this repository:
```bash
git clone https://github.com/lfontanez/tool-ollama-mama.git
cd tool-ollama-mama
```

2. Make the script executable:
```bash
chmod +x ollama-mama
```

3. Run the script:
```bash
./ollama-mama
```

## üìñ Usage

### Basic Usage

Simply run the script and follow the prompts:

```bash
./ollama-mama
```

The script will:
1. Scan all available Ollama models
2. Ask if you want to overwrite existing variants
3. Generate context window variants for each base model
4. Create Modelfiles and register new models with Ollama

### Example Output

```
INFO: Modelfiles will be saved in '/home/user/dev/ollama/Modelfiles'
Do you want to overwrite existing Modelfiles and recreate models? (y/N) n
INFO: Overwrite disabled. Existing models/files will be skipped.
--- Starting Model Scan ---
---
Processing Tag: llama2:7b
INFO: 'llama2:7b' identified as a base model.
INFO: Found Model: llama2 | Parameters: 7B | Max Context: 4096 tokens
 -> Preparing variant: llama2:7b-8k
    CREATED Modelfile: /home/user/dev/ollama/Modelfiles/my-llama2-7b-8k.modelfile
    CREATING Ollama model 'llama2:7b-8k'...
    SUCCESS: Created 'llama2:7b-8k'.
```

## ‚öôÔ∏è Configuration

### Default Settings

- **Output Directory**: `$HOME/dev/ollama/Modelfiles`
- **Starting Context**: 8192 tokens (8K)
- **Context Progression**: Doubles each iteration (8K ‚Üí 16K ‚Üí 32K ‚Üí ...)

### Customization

Edit the script to modify these variables:

```bash
# Change output directory
OUTPUT_DIR="$HOME/my-custom-path/Modelfiles"

# Change starting context size
START_CONTEXT=4096  # Start at 4K instead of 8K
```

## üìÅ Generated Files

### Modelfile Structure

Each generated Modelfile follows this format:

```dockerfile
# Modelfile for llama2:7b-16k
# Generated by script on Thu Oct 10 14:30:25 EDT 2025

FROM llama2:7b

# Set the new context window size
PARAMETER num_ctx 16384
```

### File Naming Convention

- **Modelfiles**: `my-{model-name}-{params}-{context}.modelfile`
- **Ollama Tags**: `{original-name}:{params}-{context}`

Examples:
- `my-llama2-7b-8k.modelfile` ‚Üí `llama2:7b-8k`
- `my-microsoft-DialoGPT-medium-16k.modelfile` ‚Üí `microsoft/DialoGPT:medium-16k`

## üîß Troubleshooting

### Common Issues

**Q: Script says "No Ollama models found"**
```bash
# Check if Ollama is running and has models
ollama list
```

**Q: Permission denied when creating files**
```bash
# Ensure output directory is writable
mkdir -p "$HOME/dev/ollama/Modelfiles"
chmod 755 "$HOME/dev/ollama/Modelfiles"
```

**Q: Model creation fails**
```bash
# Check Ollama service status
ollama serve  # Run in another terminal if needed
```

**Q: Git errors during execution**
```bash
# Initialize git repository if needed
git init
git add .
git commit -m "Initial commit"
```

### Debug Mode

For verbose output, run with bash debug mode:
```bash
bash -x ./ollama-mama
```

## ü§ù Contributing

Contributions are welcome! Here's how you can help:

1. **Fork** the repository
2. **Create** a feature branch (`git checkout -b feature/amazing-feature`)
3. **Commit** your changes (`git commit -m 'Add amazing feature'`)
4. **Push** to the branch (`git push origin feature/amazing-feature`)
5. **Open** a Pull Request

### Development Guidelines

- Follow existing code style and conventions
- Add comments for complex logic
- Test with multiple Ollama versions
- Update documentation for new features

## üìã Roadmap

- [ ] Support for custom context size ranges
- [ ] JSON configuration file support
- [ ] Model performance benchmarking
- [ ] Integration with Ollama model registry
- [ ] GUI version for non-technical users

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- [Ollama](https://ollama.ai/) team for the amazing local LLM platform
- Community contributors and testers
- Everyone who provided feedback and bug reports

## üìû Support

- üêõ **Bug Reports**: [GitHub Issues](https://github.com/lfontanez/tool-ollama-mama/issues)
- üí° **Feature Requests**: [GitHub Discussions](https://github.com/lfontanez/tool-ollama-mama/discussions)
- üìß **Contact**: [Your Email](mailto:your.email@example.com)

---

<div align="center">
  <strong>Made with ‚ù§Ô∏è for the Ollama community</strong>
</div>